{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b69281",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('reduced_data.csv')\n",
    "\n",
    "target_vars = df.columns[:2]\n",
    "feature_vars = df.columns[2:]\n",
    "\n",
    "correlation_with_target1 = df[feature_vars].apply(lambda x: x.corr(df[target_vars[0]])).abs()\n",
    "correlation_with_target2 = df[feature_vars].apply(lambda x: x.corr(df[target_vars[1]])).abs()\n",
    "\n",
    "max_correlation = correlation_with_target1.combine(correlation_with_target2, max)\n",
    "\n",
    "top_features = max_correlation.sort_values(ascending=False).index[:15]\n",
    "\n",
    "print(f\"Top features correlated with targets: {top_features}\")\n",
    "\n",
    "plt.figure(figsize=(15, 12))  \n",
    "sns.heatmap(df[top_features].corr().round(2), annot=True, cmap='coolwarm', fmt='.2f')  \n",
    "plt.savefig('Correlation Matrix of Top Features_Full sample.jpeg', dpi=1000, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "def create_interaction_features(df, features):\n",
    "    for feature1, feature2 in itertools.combinations(features, 2):\n",
    "        interaction_feature_name = f\"{feature1}_x_{feature2}\"\n",
    "        df[interaction_feature_name] = df[feature1] * df[feature2]\n",
    "    return df\n",
    "\n",
    "df_with_interactions = create_interaction_features(df.copy(), top_features)\n",
    "\n",
    "print(df_with_interactions.head())\n",
    "\n",
    "df_with_interactions.to_csv('data_with_interactions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431392ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgboost\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import xgboost as xgb\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "try:\n",
    "    data = pd.read_csv('data_with_interactions.csv')\n",
    "    print(\"Data loaded successfully\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Data file not found\")\n",
    "    raise\n",
    "\n",
    "X = data.iloc[:, 2:].values\n",
    "y = data.iloc[:, :2].values \n",
    "\n",
    "def composite_metric(y_true, y_pred, alpha=0.5, beta=0.1):\n",
    "    \"\"\"\n",
    "    Calculate the multi-objective composite evaluation metric.\n",
    "    :param y_true: Array of true values, shape (n_samples, n_targets).\n",
    "    :param y_pred: Array of predicted values, shape (n_samples, n_targets).\n",
    "    :param alpha: Weight of the weighted root mean square error (WRMSE) in the composite evaluation metric.\n",
    "    :param beta: Weight of the inter-target correlation in the composite evaluation metric.\n",
    "    :return: Composite evaluation metric.\n",
    "    \"\"\"\n",
    "\n",
    "    n_targets = y_true.shape[1]\n",
    "\n",
    "    mse_list = []\n",
    "    mae_list = []\n",
    "    max_mse = 0\n",
    "    max_mae = 0\n",
    "\n",
    "    for i in range(n_targets):\n",
    "        mse = mean_squared_error(y_true[:, i], y_pred[:, i])\n",
    "        mae = mean_absolute_error(y_true[:, i], y_pred[:, i])\n",
    "        mse_list.append(mse)\n",
    "        mae_list.append(mae)\n",
    "        if mse > max_mse:\n",
    "            max_mse = mse\n",
    "        if mae > max_mae:\n",
    "            max_mae = mae\n",
    "\n",
    "    normalized_mse = [mse / max_mse for mse in mse_list]\n",
    "    normalized_mae = [mae / max_mae for mae in mae_list]\n",
    "\n",
    "    inverse_mse = [1 / mse if mse != 0 else 0 for mse in normalized_mse]\n",
    "    sum_inverse_mse = sum(inverse_mse)\n",
    "    weights = [inv_mse / sum_inverse_mse for inv_mse in inverse_mse]\n",
    "\n",
    "    wrmse = np.sqrt(sum([w * mse for w, mse in zip(weights, normalized_mse)]))\n",
    "    wmae = sum([w * mae for w, mae in zip(weights, normalized_mae)])\n",
    "\n",
    "    correlation_sum = 0\n",
    "    for i in range(n_targets):\n",
    "        for j in range(i + 1, n_targets):\n",
    "            corr, _ = pearsonr(y_true[:, i], y_true[:, j])\n",
    "            correlation_sum += corr * mse_list[i] * mse_list[j]\n",
    "\n",
    "    composite_score = alpha * wrmse + (1 - alpha) * wmae + beta * correlation_sum\n",
    "    return composite_score\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "\n",
    "def train_and_evaluate(X, y, alpha=0.5, beta=0.1):\n",
    "    composite_scores = []\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    for train_index, val_index in kf.split(X_train):\n",
    "        X_tr, X_val = X_train[train_index], X_train[val_index]\n",
    "        y_tr, y_val = y_train[train_index], y_train[val_index]\n",
    "\n",
    "        model1 = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, random_state=42)\n",
    "        model2 = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, random_state=42)\n",
    "\n",
    "        model1.fit(X_tr, y_tr[:, 0])\n",
    "        model2.fit(X_tr, y_tr[:, 1])\n",
    "\n",
    "        y_pred1 = model1.predict(X_val)\n",
    "        y_pred2 = model2.predict(X_val)\n",
    "\n",
    "        y_val_combined = np.vstack((y_val[:, 0], y_val[:, 1])).T\n",
    "        y_pred_combined = np.vstack((y_pred1, y_pred2)).T\n",
    "\n",
    "        score = composite_metric(y_val_combined, y_pred_combined, alpha, beta)\n",
    "        composite_scores.append(score)\n",
    "\n",
    "    mean_composite_score = np.mean(composite_scores)\n",
    "\n",
    "    model1.fit(X_train, y_train[:, 0])\n",
    "    model2.fit(X_train, y_train[:, 1])\n",
    "\n",
    "    y_pred1_test = model1.predict(X_test)\n",
    "    y_pred2_test = model2.predict(X_test)\n",
    "\n",
    "    y_test_combined = np.vstack((y_test[:, 0], y_test[:, 1])).T\n",
    "    y_pred_combined_test = np.vstack((y_pred1_test, y_pred2_test)).T\n",
    "\n",
    "    test_score = composite_metric(y_test_combined, y_pred_combined_test, alpha, beta)\n",
    "    print(f\"Test Composite Score: {test_score}\")\n",
    "\n",
    "    return mean_composite_score, test_score\n",
    "\n",
    "mean_composite_score, test_composite_score = train_and_evaluate(X, y)\n",
    "print(f\"Mean Composite Score (Cross-validation): {mean_composite_score}\")\n",
    "print(f\"Test Composite Score: {test_composite_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0ca645",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adboost\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "try:\n",
    "    data = pd.read_csv('data_with_interactions.csv')\n",
    "    print(\"Data loaded successfully\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Data file not found\")\n",
    "    raise\n",
    "\n",
    "X = data.iloc[:, 2:].values\n",
    "y = data.iloc[:, :2].values  \n",
    "\n",
    "def composite_metric(y_true, y_pred, alpha=0.5, beta=0.1):\n",
    "    \"\"\"\n",
    "    Calculate the multi-objective composite evaluation metric.\n",
    "    :param y_true: Array of true values, shape (n_samples, n_targets).\n",
    "    :param y_pred: Array of predicted values, shape (n_samples, n_targets).\n",
    "    :param alpha: Weight of the weighted root mean square error (WRMSE) in the composite evaluation metric.\n",
    "    :param beta: Weight of the inter-target correlation in the composite evaluation metric.\n",
    "    :return: Composite evaluation metric.\n",
    "    \"\"\"\n",
    "    n_targets = y_true.shape[1]\n",
    "\n",
    "\n",
    "    mse_list = []\n",
    "    mae_list = []\n",
    "    max_mse = 0\n",
    "    max_mae = 0\n",
    "\n",
    "    for i in range(n_targets):\n",
    "        mse = mean_squared_error(y_true[:, i], y_pred[:, i])\n",
    "        mae = mean_absolute_error(y_true[:, i], y_pred[:, i])\n",
    "        mse_list.append(mse)\n",
    "        mae_list.append(mae)\n",
    "        if mse > max_mse:\n",
    "            max_mse = mse\n",
    "        if mae > max_mae:\n",
    "            max_mae = mae\n",
    "\n",
    "  \n",
    "    normalized_mse = [mse / max_mse for mse in mse_list]\n",
    "    normalized_mae = [mae / max_mae for mae in mae_list]\n",
    "\n",
    "  \n",
    "    inverse_mse = [1 / mse if mse != 0 else 0 for mse in normalized_mse]\n",
    "    sum_inverse_mse = sum(inverse_mse)\n",
    "    weights = [inv_mse / sum_inverse_mse for inv_mse in inverse_mse]\n",
    "\n",
    " \n",
    "    wrmse = np.sqrt(sum([w * mse for w, mse in zip(weights, normalized_mse)]))\n",
    "    wmae = sum([w * mae for w, mae in zip(weights, normalized_mae)])\n",
    "\n",
    "    correlation_sum = 0\n",
    "    for i in range(n_targets):\n",
    "        for j in range(i + 1, n_targets):\n",
    "            corr, _ = pearsonr(y_true[:, i], y_true[:, j])\n",
    "            correlation_sum += corr * mse_list[i] * mse_list[j]\n",
    "\n",
    "\n",
    "    composite_score = alpha * wrmse + (1 - alpha) * wmae + beta * correlation_sum\n",
    "    return composite_score\n",
    "\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "\n",
    "def train_and_evaluate(X, y, alpha=0.5, beta=0.1):\n",
    "    composite_scores = []\n",
    "\n",
    "  \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    for train_index, val_index in kf.split(X_train):\n",
    "        X_tr, X_val = X_train[train_index], X_train[val_index]\n",
    "        y_tr, y_val = y_train[train_index], y_train[val_index]\n",
    "\n",
    "        model1 = AdaBoostRegressor(n_estimators=100, random_state=42)\n",
    "        model2 = AdaBoostRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "        model1.fit(X_tr, y_tr[:, 0])\n",
    "        model2.fit(X_tr, y_tr[:, 1])\n",
    "\n",
    "        y_pred1 = model1.predict(X_val)\n",
    "        y_pred2 = model2.predict(X_val)\n",
    "\n",
    "        y_val_combined = np.vstack((y_val[:, 0], y_val[:, 1])).T\n",
    "        y_pred_combined = np.vstack((y_pred1, y_pred2)).T\n",
    "\n",
    "        score = composite_metric(y_val_combined, y_pred_combined, alpha, beta)\n",
    "        composite_scores.append(score)\n",
    "\n",
    "    mean_composite_score = np.mean(composite_scores)\n",
    "\n",
    "\n",
    "    model1.fit(X_train, y_train[:, 0])\n",
    "    model2.fit(X_train, y_train[:, 1])\n",
    "\n",
    "    y_pred1_test = model1.predict(X_test)\n",
    "    y_pred2_test = model2.predict(X_test)\n",
    "\n",
    "    y_test_combined = np.vstack((y_test[:, 0], y_test[:, 1])).T\n",
    "    y_pred_combined_test = np.vstack((y_pred1_test, y_pred2_test)).T\n",
    "\n",
    "    test_score = composite_metric(y_test_combined, y_pred_combined_test, alpha, beta)\n",
    "    print(f\"Test Composite Score: {test_score}\")\n",
    "\n",
    "    return mean_composite_score, test_score\n",
    "\n",
    "mean_composite_score, test_composite_score = train_and_evaluate(X, y)\n",
    "print(f\"Mean Composite Score (Cross-validation): {mean_composite_score}\")\n",
    "print(f\"Test Composite Score: {test_composite_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7664131d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#catboost\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from catboost import CatBoostRegressor\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "\n",
    "try:\n",
    "    data = pd.read_csv('data_with_interactions.csv')\n",
    "    print(\"Data loaded successfully\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Data file not found\")\n",
    "    raise\n",
    "\n",
    "\n",
    "X = data.iloc[:, 2:].values\n",
    "y = data.iloc[:, :2].values \n",
    "\n",
    "def composite_metric(y_true, y_pred, alpha=0.5, beta=0.1):\n",
    "    \"\"\"\n",
    "    Calculate the multi-objective composite evaluation metric.\n",
    "    :param y_true: Array of true values, shape (n_samples, n_targets).\n",
    "    :param y_pred: Array of predicted values, shape (n_samples, n_targets).\n",
    "    :param alpha: Weight of the weighted root mean square error (WRMSE) in the composite evaluation metric.\n",
    "    :param beta: Weight of the inter-target correlation in the composite evaluation metric.\n",
    "    :return: Composite evaluation metric.\n",
    "    \"\"\"\n",
    "    n_targets = y_true.shape[1]\n",
    "\n",
    "    mse_list = []\n",
    "    mae_list = []\n",
    "    max_mse = 0\n",
    "    max_mae = 0\n",
    "\n",
    "    for i in range(n_targets):\n",
    "        mse = mean_squared_error(y_true[:, i], y_pred[:, i])\n",
    "        mae = mean_absolute_error(y_true[:, i], y_pred[:, i])\n",
    "        mse_list.append(mse)\n",
    "        mae_list.append(mae)\n",
    "        if mse > max_mse:\n",
    "            max_mse = mse\n",
    "        if mae > max_mae:\n",
    "            max_mae = mae\n",
    "\n",
    "    normalized_mse = [mse / max_mse for mse in mse_list]\n",
    "    normalized_mae = [mae / max_mae for mae in mae_list]\n",
    "\n",
    "    inverse_mse = [1 / mse if mse != 0 else 0 for mse in normalized_mse]\n",
    "    sum_inverse_mse = sum(inverse_mse)\n",
    "    weights = [inv_mse / sum_inverse_mse for inv_mse in inverse_mse]\n",
    "\n",
    "    wrmse = np.sqrt(sum([w * mse for w, mse in zip(weights, normalized_mse)]))\n",
    "    wmae = sum([w * mae for w, mae in zip(weights, normalized_mae)])\n",
    "\n",
    "    correlation_sum = 0\n",
    "    for i in range(n_targets):\n",
    "        for j in range(i + 1, n_targets):\n",
    "            corr, _ = pearsonr(y_true[:, i], y_true[:, j])\n",
    "            correlation_sum += corr * mse_list[i] * mse_list[j]\n",
    "\n",
    "    composite_score = alpha * wrmse + (1 - alpha) * wmae + beta * correlation_sum\n",
    "    return composite_score\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "def train_and_evaluate(X, y, alpha=0.5, beta=0.1):\n",
    "    composite_scores = []\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    for train_index, val_index in kf.split(X_train):\n",
    "        X_tr, X_val = X_train[train_index], X_train[val_index]\n",
    "        y_tr, y_val = y_train[train_index], y_train[val_index]\n",
    "\n",
    "        model1 = CatBoostRegressor(iterations=100, random_seed=42, verbose=0)\n",
    "        model2 = CatBoostRegressor(iterations=100, random_seed=42, verbose=0)\n",
    "\n",
    "        model1.fit(X_tr, y_tr[:, 0])\n",
    "        model2.fit(X_tr, y_tr[:, 1])\n",
    "\n",
    "        y_pred1 = model1.predict(X_val)\n",
    "        y_pred2 = model2.predict(X_val)\n",
    "\n",
    "        y_val_combined = np.vstack((y_val[:, 0], y_val[:, 1])).T\n",
    "        y_pred_combined = np.vstack((y_pred1, y_pred2)).T\n",
    "\n",
    "        score = composite_metric(y_val_combined, y_pred_combined, alpha, beta)\n",
    "        composite_scores.append(score)\n",
    "\n",
    "    mean_composite_score = np.mean(composite_scores)\n",
    "\n",
    "    model1.fit(X_train, y_train[:, 0])\n",
    "    model2.fit(X_train, y_train[:, 1])\n",
    "\n",
    "    y_pred1_test = model1.predict(X_test)\n",
    "    y_pred2_test = model2.predict(X_test)\n",
    "\n",
    "    y_test_combined = np.vstack((y_test[:, 0], y_test[:, 1])).T\n",
    "    y_pred_combined_test = np.vstack((y_pred1_test, y_pred2_test)).T\n",
    "\n",
    "    test_score = composite_metric(y_test_combined, y_pred_combined_test, alpha, beta)\n",
    "    print(f\"Test Composite Score: {test_score}\")\n",
    "\n",
    "    return mean_composite_score, test_score\n",
    "\n",
    "mean_composite_score, test_composite_score = train_and_evaluate(X, y)\n",
    "print(f\"Mean Composite Score (Cross-validation): {mean_composite_score}\")\n",
    "print(f\"Test Composite Score: {test_composite_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301931a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GBRT\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "try:\n",
    "    data = pd.read_csv('data_with_interactions.csv')\n",
    "    print(\"Data loaded successfully\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Data file not found\")\n",
    "    raise\n",
    "\n",
    "X = data.iloc[:, 2:].values\n",
    "y = data.iloc[:, :2].values  \n",
    "\n",
    "def composite_metric(y_true, y_pred, alpha=0.5, beta=0.1):\n",
    "    \"\"\"\n",
    "    Calculate the multi-objective composite evaluation metric.\n",
    "    :param y_true: Array of true values, shape (n_samples, n_targets).\n",
    "    :param y_pred: Array of predicted values, shape (n_samples, n_targets).\n",
    "    :param alpha: Weight of the weighted root mean square error (WRMSE) in the composite evaluation metric.\n",
    "    :param beta: Weight of the inter-target correlation in the composite evaluation metric.\n",
    "    :return: Composite evaluation metric.\n",
    "    \"\"\"\n",
    "    n_targets = y_true.shape[1]\n",
    "\n",
    "    mse_list = []\n",
    "    mae_list = []\n",
    "    max_mse = 0\n",
    "    max_mae = 0\n",
    "\n",
    "    for i in range(n_targets):\n",
    "        mse = mean_squared_error(y_true[:, i], y_pred[:, i])\n",
    "        mae = mean_absolute_error(y_true[:, i], y_pred[:, i])\n",
    "        mse_list.append(mse)\n",
    "        mae_list.append(mae)\n",
    "        if mse > max_mse:\n",
    "            max_mse = mse\n",
    "        if mae > max_mae:\n",
    "            max_mae = mae\n",
    "\n",
    "    normalized_mse = [mse / max_mse for mse in mse_list]\n",
    "    normalized_mae = [mae / max_mae for mae in mae_list]\n",
    "\n",
    "    inverse_mse = [1 / mse if mse != 0 else 0 for mse in normalized_mse]\n",
    "    sum_inverse_mse = sum(inverse_mse)\n",
    "    weights = [inv_mse / sum_inverse_mse for inv_mse in inverse_mse]\n",
    "\n",
    "    wrmse = np.sqrt(sum([w * mse for w, mse in zip(weights, normalized_mse)]))\n",
    "    wmae = sum([w * mae for w, mae in zip(weights, normalized_mae)])\n",
    "\n",
    "    correlation_sum = 0\n",
    "    for i in range(n_targets):\n",
    "        for j in range(i + 1, n_targets):\n",
    "            corr, _ = pearsonr(y_true[:, i], y_true[:, j])\n",
    "            correlation_sum += corr * mse_list[i] * mse_list[j]\n",
    "\n",
    "    composite_score = alpha * wrmse + (1 - alpha) * wmae + beta * correlation_sum\n",
    "    return composite_score\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "def train_and_evaluate(X, y, alpha=0.5, beta=0.1):\n",
    "    composite_scores = []\n",
    "\n",
    "   \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    for train_index, val_index in kf.split(X_train):\n",
    "        X_tr, X_val = X_train[train_index], X_train[val_index]\n",
    "        y_tr, y_val = y_train[train_index], y_train[val_index]\n",
    "\n",
    "        model1 = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "        model2 = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "        model1.fit(X_tr, y_tr[:, 0])\n",
    "        model2.fit(X_tr, y_tr[:, 1])\n",
    "\n",
    "        y_pred1 = model1.predict(X_val)\n",
    "        y_pred2 = model2.predict(X_val)\n",
    "\n",
    "        y_val_combined = np.vstack((y_val[:, 0], y_val[:, 1])).T\n",
    "        y_pred_combined = np.vstack((y_pred1, y_pred2)).T\n",
    "\n",
    "        score = composite_metric(y_val_combined, y_pred_combined, alpha, beta)\n",
    "        composite_scores.append(score)\n",
    "\n",
    "    mean_composite_score = np.mean(composite_scores)\n",
    "\n",
    "\n",
    "    model1.fit(X_train, y_train[:, 0])\n",
    "    model2.fit(X_train, y_train[:, 1])\n",
    "\n",
    "    y_pred1_test = model1.predict(X_test)\n",
    "    y_pred2_test = model2.predict(X_test)\n",
    "\n",
    "    y_test_combined = np.vstack((y_test[:, 0], y_test[:, 1])).T\n",
    "    y_pred_combined_test = np.vstack((y_pred1_test, y_pred2_test)).T\n",
    "\n",
    "    test_score = composite_metric(y_test_combined, y_pred_combined_test, alpha, beta)\n",
    "    print(f\"Test Composite Score: {test_score}\")\n",
    "\n",
    "    return mean_composite_score, test_score\n",
    "\n",
    "\n",
    "mean_composite_score, test_composite_score = train_and_evaluate(X, y)\n",
    "print(f\"Mean Composite Score (Cross-validation): {mean_composite_score}\")\n",
    "print(f\"Test Composite Score: {test_composite_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02595de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RF\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "\n",
    "try:\n",
    "    data = pd.read_csv('data_with_interactions.csv')\n",
    "    print(\"Data loaded successfully\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Data file not found\")\n",
    "    raise\n",
    "\n",
    "\n",
    "X = data.iloc[:, 2:].values\n",
    "y = data.iloc[:, :2].values  \n",
    "\n",
    "def composite_metric(y_true, y_pred, alpha=0.5, beta=0.1):\n",
    "    \"\"\"\n",
    "    Calculate the multi-objective composite evaluation metric.\n",
    "    :param y_true: Array of true values, shape (n_samples, n_targets).\n",
    "    :param y_pred: Array of predicted values, shape (n_samples, n_targets).\n",
    "    :param alpha: Weight of the weighted root mean square error (WRMSE) in the composite evaluation metric.\n",
    "    :param beta: Weight of the inter-target correlation in the composite evaluation metric.\n",
    "    :return: Composite evaluation metric.\n",
    "    \"\"\"\n",
    "    n_targets = y_true.shape[1]\n",
    "\n",
    "   \n",
    "    mse_list = []\n",
    "    mae_list = []\n",
    "    max_mse = 0\n",
    "    max_mae = 0\n",
    "\n",
    "    for i in range(n_targets):\n",
    "        mse = mean_squared_error(y_true[:, i], y_pred[:, i])\n",
    "        mae = mean_absolute_error(y_true[:, i], y_pred[:, i])\n",
    "        mse_list.append(mse)\n",
    "        mae_list.append(mae)\n",
    "        if mse > max_mse:\n",
    "            max_mse = mse\n",
    "        if mae > max_mae:\n",
    "            max_mae = mae\n",
    "\n",
    " \n",
    "    normalized_mse = [mse / max_mse for mse in mse_list]\n",
    "    normalized_mae = [mae / max_mae for mae in mae_list]\n",
    "\n",
    "\n",
    "    inverse_mse = [1 / mse if mse != 0 else 0 for mse in normalized_mse]\n",
    "    sum_inverse_mse = sum(inverse_mse)\n",
    "    weights = [inv_mse / sum_inverse_mse for inv_mse in inverse_mse]\n",
    "\n",
    "  \n",
    "    wrmse = np.sqrt(sum([w * mse for w, mse in zip(weights, normalized_mse)]))\n",
    "    wmae = sum([w * mae for w, mae in zip(weights, normalized_mae)])\n",
    "\n",
    "\n",
    "    correlation_sum = 0\n",
    "    for i in range(n_targets):\n",
    "        for j in range(i + 1, n_targets):\n",
    "            corr, _ = pearsonr(y_true[:, i], y_true[:, j])\n",
    "            correlation_sum += corr * mse_list[i] * mse_list[j]\n",
    "\n",
    "\n",
    "    composite_score = alpha * wrmse + (1 - alpha) * wmae + beta * correlation_sum\n",
    "    return composite_score\n",
    "\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "\n",
    "def train_and_evaluate(X, y, alpha=0.5, beta=0.1):\n",
    "    composite_scores = []\n",
    "\n",
    "   \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    " \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    for train_index, val_index in kf.split(X_train):\n",
    "        X_tr, X_val = X_train[train_index], X_train[val_index]\n",
    "        y_tr, y_val = y_train[train_index], y_train[val_index]\n",
    "\n",
    "        model1 = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "        model2 = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "        model1.fit(X_tr, y_tr[:, 0])\n",
    "        model2.fit(X_tr, y_tr[:, 1])\n",
    "\n",
    "        y_pred1 = model1.predict(X_val)\n",
    "        y_pred2 = model2.predict(X_val)\n",
    "\n",
    "        y_val_combined = np.vstack((y_val[:, 0], y_val[:, 1])).T\n",
    "        y_pred_combined = np.vstack((y_pred1, y_pred2)).T\n",
    "\n",
    "        score = composite_metric(y_val_combined, y_pred_combined, alpha, beta)\n",
    "        composite_scores.append(score)\n",
    "\n",
    "    mean_composite_score = np.mean(composite_scores)\n",
    "\n",
    " \n",
    "    model1.fit(X_train, y_train[:, 0])\n",
    "    model2.fit(X_train, y_train[:, 1])\n",
    "\n",
    "    y_pred1_test = model1.predict(X_test)\n",
    "    y_pred2_test = model2.predict(X_test)\n",
    "\n",
    "    y_test_combined = np.vstack((y_test[:, 0], y_test[:, 1])).T\n",
    "    y_pred_combined_test = np.vstack((y_pred1_test, y_pred2_test)).T\n",
    "\n",
    "    test_score = composite_metric(y_test_combined, y_pred_combined_test, alpha, beta)\n",
    "    print(f\"Test Composite Score: {test_score}\")\n",
    "\n",
    "    return mean_composite_score, test_score\n",
    "\n",
    "\n",
    "mean_composite_score, test_composite_score = train_and_evaluate(X, y)\n",
    "print(f\"Mean Composite Score (Cross-validation): {mean_composite_score}\")\n",
    "print(f\"Test Composite Score: {test_composite_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31956f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ExtraTree\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "\n",
    "try:\n",
    "    data = pd.read_csv('data_with_interactions.csv')\n",
    "    print(\"Data loaded successfully\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Data file not found\")\n",
    "    raise\n",
    "\n",
    "\n",
    "X = data.iloc[:, 2:].values\n",
    "y = data.iloc[:, :2].values  \n",
    "\n",
    "def composite_metric(y_true, y_pred, alpha=0.5, beta=0.1):\n",
    "    \"\"\"\n",
    "    Calculate the multi-objective composite evaluation metric.\n",
    "    :param y_true: Array of true values, shape (n_samples, n_targets).\n",
    "    :param y_pred: Array of predicted values, shape (n_samples, n_targets).\n",
    "    :param alpha: Weight of the weighted root mean square error (WRMSE) in the composite evaluation metric.\n",
    "    :param beta: Weight of the inter-target correlation in the composite evaluation metric.\n",
    "    :return: Composite evaluation metric.\n",
    "    \"\"\"\n",
    "    n_targets = y_true.shape[1]\n",
    "\n",
    "\n",
    "    mse_list = []\n",
    "    mae_list = []\n",
    "    max_mse = 0\n",
    "    max_mae = 0\n",
    "\n",
    "    for i in range(n_targets):\n",
    "        mse = mean_squared_error(y_true[:, i], y_pred[:, i])\n",
    "        mae = mean_absolute_error(y_true[:, i], y_pred[:, i])\n",
    "        mse_list.append(mse)\n",
    "        mae_list.append(mae)\n",
    "        if mse > max_mse:\n",
    "            max_mse = mse\n",
    "        if mae > max_mae:\n",
    "            max_mae = mae\n",
    "\n",
    "\n",
    "    normalized_mse = [mse / max_mse for mse in mse_list]\n",
    "    normalized_mae = [mae / max_mae for mae in mae_list]\n",
    "\n",
    "\n",
    "    inverse_mse = [1 / mse if mse != 0 else 0 for mse in normalized_mse]\n",
    "    sum_inverse_mse = sum(inverse_mse)\n",
    "    weights = [inv_mse / sum_inverse_mse for inv_mse in inverse_mse]\n",
    "\n",
    "\n",
    "    wrmse = np.sqrt(sum([w * mse for w, mse in zip(weights, normalized_mse)]))\n",
    "    wmae = sum([w * mae for w, mae in zip(weights, normalized_mae)])\n",
    "\n",
    "\n",
    "    correlation_sum = 0\n",
    "    for i in range(n_targets):\n",
    "        for j in range(i + 1, n_targets):\n",
    "            corr, _ = pearsonr(y_true[:, i], y_true[:, j])\n",
    "            correlation_sum += corr * mse_list[i] * mse_list[j]\n",
    "\n",
    " \n",
    "    composite_score = alpha * wrmse + (1 - alpha) * wmae + beta * correlation_sum\n",
    "    return composite_score\n",
    "\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "\n",
    "def train_and_evaluate(X, y, alpha=0.5, beta=0.1):\n",
    "    composite_scores = []\n",
    "\n",
    " \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    for train_index, val_index in kf.split(X_train):\n",
    "        X_tr, X_val = X_train[train_index], X_train[val_index]\n",
    "        y_tr, y_val = y_train[train_index], y_train[val_index]\n",
    "\n",
    "        model1 = ExtraTreesRegressor(n_estimators=100, random_state=42)\n",
    "        model2 = ExtraTreesRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "        model1.fit(X_tr, y_tr[:, 0])\n",
    "        model2.fit(X_tr, y_tr[:, 1])\n",
    "\n",
    "        y_pred1 = model1.predict(X_val)\n",
    "        y_pred2 = model2.predict(X_val)\n",
    "\n",
    "        y_val_combined = np.vstack((y_val[:, 0], y_val[:, 1])).T\n",
    "        y_pred_combined = np.vstack((y_pred1, y_pred2)).T\n",
    "\n",
    "        score = composite_metric(y_val_combined, y_pred_combined, alpha, beta)\n",
    "        composite_scores.append(score)\n",
    "\n",
    "    mean_composite_score = np.mean(composite_scores)\n",
    "\n",
    "\n",
    "    model1.fit(X_train, y_train[:, 0])\n",
    "    model2.fit(X_train, y_train[:, 1])\n",
    "\n",
    "    y_pred1_test = model1.predict(X_test)\n",
    "    y_pred2_test = model2.predict(X_test)\n",
    "\n",
    "    y_test_combined = np.vstack((y_test[:, 0], y_test[:, 1])).T\n",
    "    y_pred_combined_test = np.vstack((y_pred1_test, y_pred2_test)).T\n",
    "\n",
    "    test_score = composite_metric(y_test_combined, y_pred_combined_test, alpha, beta)\n",
    "    print(f\"Test Composite Score: {test_score}\")\n",
    "\n",
    "    return mean_composite_score, test_score\n",
    "\n",
    "\n",
    "mean_composite_score, test_composite_score = train_and_evaluate(X, y)\n",
    "print(f\"Mean Composite Score (Cross-validation): {mean_composite_score}\")\n",
    "print(f\"Test Composite Score: {test_composite_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
